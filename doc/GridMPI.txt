QUICK USAGE OF GRIDMPI WITH PSPACER
===================================
April 13, 2006

NOTES: THIS VERSION IS EXPERIMENTAL AND ONLY SUPPORTED IN LINUX

INSTALLATION
------------

Download GridMPI (version 1.0 later) and PSPacer (version 2.0 later)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

	$ tar zxvf pspacer-2.0.tar.gz
	$ tar zxvf gridmpi-1.0.tar.gz


Build and install PSPacer RPM package
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
If you use RedHat Linux, issue commands as follows:

	$ cd pspacer-2.0
	$ make dist
	$ rpmbuild -tb pspacer-2.0.tar.gz

Install this RPM package to all hosts.

	$ su
	# rpm -ivh <RPM_PATH>/RPMS/i386/pspacer-2.0-1.i386.rpm

NOTE: The source code of iproute2 has to be placed on /opt/iprote2.
PSPacer module is depend on the Linux kernel version.
FYI, see pspacer/doc/usage.en.txt.


Setup pspd configuration files
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/etc/sysconfig/pspd/[add|del] are called by /etc/init.d/pspd
script to setup and remove PSPacer module.
Edit these files to make these fit your environment.

FYI, see pspd.txt about pspd.


Setup environment variable _PSP_OPT
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Set the environment variable _PSP_OPT to specify pairs of interface 
device such as eth0 and class-id such as 1:1. See tc (8) man page 
about class-id.

For example, add a following line to .bashrc etc.

	export _PSP_OPT=eth0:1:1,eth1:1:1


Start pspd
~~~~~~~~~~
Install the following command on all hosts.

	# /etc/init.d/pspd start

(OPTIONAL) If you want to start pspd at boot time, issue the 
following command.

	# /sbin/chkconfig --add pspd


Configure with "--with-libpsp", make and make install
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
You only need to add a configure option "--with-libpsp".

	$ cd gridmpi-1.0
	$ ./configure --with-libpsp
	$ make
	$ make install

FYI, see GridMPI documentations.


Run your MPI application
~~~~~~~~~~~~~~~~~~~~~~~~
Usage of mpicc and (grid)mpirun is same whether PSPacer is enabled.

Currently, PSPacer is only effective to use MPI_Alltoall and MPI_Alltoallv.


Stop pspd
~~~~~~~~~

	# /etc/init.d/pspd stop


EXAMPLE SETTING
---------------

Two clusters are connected by gigabit Ethernet and each cluster is 
comprised of 16 nodes as follows:

	cluster A (16 nodes)         cluster B (16 nodes)
	 202.241.93.128/25    <--->   202.241.94.128/25

To realize a transmission bandwidth control for each intra-cluster 
communication and inter-cluster communication, you need to classify 
traffic and control the bandwidths each other.  In the example above, 
setup tc filters in a /etc/sysconfig/pspd/add script as follows:

/etc/sysconfig/pspd/add in cluster A:

	DEV="eth1"
	/sbin/ethtool -K $DEV tso off					<1>
	/sbin/ifconfig $DEV txqueuelen 10000				<2>
	/sbin/tc qdisc add dev $DEV root handle 1: psp default 1
	/sbin/tc class add dev $DEV parent 1: classid 1:1 psp mode 0
	/sbin/tc class add dev $DEV parent 1: classid 1:2 psp mode 0
	/sbin/tc qdisc add dev $DEV parent 1:1 handle 10: pfifo
	/sbin/tc qdisc add dev $DEV parent 1:2 handle 20: pfifo

	U32="/sbin/tc filter add dev $DEV protocol ip parent 1: pref 1 u32"
	$U32 match ip dst 202.241.94.128/25 classid 1:2

<1> PSPacer is not supporting TCP Segmentation Offload (TSO), 
you have to disable TSO before you install it.
<2> see FAQ page "How can I achieve Gigabit speeds on Long Fat 
Networks using TCP/IP?" (https://gridmpi.org/pspacer-1.0/faq.en.jsp)

/etc/sysconfig/pspd/add in cluster B:

	DEV="eth1"
	/sbin/ethtool -K $DEV tso off
	/sbin/ifconfig $DEV txqueuelen 10000
	/sbin/tc qdisc add dev $DEV root handle 1: psp default 1
	/sbin/tc class add dev $DEV parent 1: classid 1:1 psp mode 0
	/sbin/tc class add dev $DEV parent 1: classid 1:2 psp mode 0
	/sbin/tc qdisc add dev $DEV parent 1:1 handle 10: pfifo
	/sbin/tc qdisc add dev $DEV parent 1:2 handle 20: pfifo

	U32="/sbin/tc filter add dev $DEV protocol ip parent 1: pref 1 u32"
	$U32 match ip dst 202.241.93.128/25 classid 1:2


The psp of classid 1:1 works for intra-cluster communication.  On the
other hand, the psp of classid 1:2 works for inter-cluster communication.
And then, setup environment variables as follows:

	export _PSP_OPT=eth1:1:1,eth1:1:2
